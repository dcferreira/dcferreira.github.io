[{"authors":null,"categories":null,"content":"This was a short project I did with a random team for a weekend-long Hackathon. The idea was to take the most liked tweets for a specific user, and use a Large Language Model to generate new tweets in this user’s style.\nAt the moment you can try it out at https://tweetfake.dcferreira.com (need to be logged in to Twitter), although it’s not clear for how long this link will stay up. There is also a short video in the devpost project page.\n","date":1670716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670716800,"objectID":"78edb8babe78801a704cf73897c1bb69","permalink":"https://dcferreira.com/project/tweetfake/","publishdate":"2022-12-11T00:00:00Z","relpermalink":"/project/tweetfake/","section":"project","summary":"This was a short project I did with a random team for a weekend-long Hackathon. The idea was to take the most liked tweets for a specific user, and use a Large Language Model to generate new tweets in this user’s style.","tags":["NLP"],"title":"Tweet Fake","type":"project"},{"authors":null,"categories":null,"content":"A simple browser extension that hides YouTube video length for user-selected channels. Unlike other similar browser extensions, this one also hides the video length in video thumbnails.\nYou can easily install it from the Chrome Web Store.\n","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"cd93aba32aec085e8a42dcfce593d476","permalink":"https://dcferreira.com/project/infinity-for-youtube/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/project/infinity-for-youtube/","section":"project","summary":"A simple browser extension that hides YouTube video length for user-selected channels. Unlike other similar browser extensions, this one also hides the video length in video thumbnails.\nYou can easily install it from the Chrome Web Store.","tags":["Webdev"],"title":"Infinity for Youtube","type":"project"},{"authors":["Daniel C. Ferreira"],"categories":["Spark","Databricks"],"content":"Overview I often run into a problem when writing UDFs on Databricks, where I need some to access some object that pickle can’t serialize. Often times this is just something that comes from some external library, and so fixing the code is not a practical solution.\nAn easy solution to this is to initialize the object inside the UDF itself. This avoids the need for serialization, but it introduces a new problem: the object is initialized for every run of the UDF, hitting performance.\nThe solution that addresses these 2 problems is to cache the object initialization. Then, each executor initializes the object only once.\nThe Problem Here is a simple example:\nimport time from lxml.etree import HTMLParser # `spark` is the spark context, on databricks it is a global variable that\u0026#39;s always available df = spark.createDataFrame([{\u0026#34;n\u0026#34;: n} for n in range(10000)]) class Slow: def __init__(self): self.parser = HTMLParser() time.sleep(0.01) def double(self, x: int) -\u0026gt; int: return 2 * x slow_global = Slow() @udf(\u0026#34;int\u0026#34;) def f_error(n): return slow_global.double(n) When actually executing the UDF\ndf.select(\u0026#34;n\u0026#34;, f_error(\u0026#34;n\u0026#34;)).collect() we get the error\nPicklingError: Could not serialize object: TypeError: can\u0026#39;t pickle lxml.etree.HTMLParser objects Naive Solution The naive solution is to initialize the object in each run of the UDF:\n@udf(\u0026#34;int\u0026#34;) def f(n): slow = Slow() return slow.double(n) This works\ndf.select(\u0026#34;n\u0026#34;, f(\u0026#34;n\u0026#34;)).collect() but it’s very inefficient.\nOn a cluster with 2 i3.xlarge workers on AWS, executing this took me around 25 seconds.\nOptimized Solution The solution is then to cache the object initialization. For this, we need the cachetools library. On Databricks, you can install it by running the following cell\n%pip install cachetools  We can’t use lru_cache from the standard library, because it requires serialization. Trying it gives us the error: PicklingError: Could not serialize object: AttributeError: \u0026#39;functools._lru_cache_wrapper\u0026#39; object has no attribute \u0026#39;__bases__\u0026#39;   Usage is very simple:\nfrom cachetools import cached @cached(cache={}) def get_slow(): return Slow() @udf(\u0026#34;int\u0026#34;) def f_cached(n): slow = get_slow() return slow.double(n) Executing it\ndf.select(\u0026#34;n\u0026#34;, f_cached(\u0026#34;n\u0026#34;)).collect() took around 0.5 seconds, in the same cluster as above.\n","date":1647883800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647883800,"objectID":"70ebad5652ed1089e6f2d52e9dc93813","permalink":"https://dcferreira.com/post/2022-03-spark-serialization/","publishdate":"2022-03-21T17:30:00Z","relpermalink":"/post/2022-03-spark-serialization/","section":"post","summary":"How to avoid `PicklingError` on custom UDFs on Databricks/Spark, while keeping optimal performance.","tags":["Spark","Databricks"],"title":"Efficient UDFs on Databricks with unpickleable objects","type":"post"},{"authors":["Félix Iglesias Vázquez","Daniel C. Ferreira","Gernot Vormayr","Maximilian Bachl","Tanja Zseby"],"categories":null,"content":"","date":1580342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580342400,"objectID":"e533a110dfaa3ca4a458371794ddb620","permalink":"https://dcferreira.com/publication/ntarc/","publishdate":"2020-10-30T00:00:00Z","relpermalink":"/publication/ntarc/","section":"publication","summary":"We present Network Traffic Analysis Research Curation (NTARC), a data model to store key information about network traffic analysis research.","tags":[],"title":"NTARC: A Data Model for the Systematic Review of Network Traffic Analysis Research","type":"publication"},{"authors":null,"categories":null,"content":"","date":1572393600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572393600,"objectID":"e177ab8b66e73093bc342f05b68834fd","permalink":"https://dcferreira.com/project/deep-architect/","publishdate":"2019-10-30T00:00:00Z","relpermalink":"/project/deep-architect/","section":"project","summary":"DeepArchitect is a framework for automatically searching over computational graphs in arbitrary domains, designed with a focus on modularity, ease of use, reusability, and extensibility.","tags":["Deep Learning"],"title":"DeepArchitect","type":"project"},{"authors":["Renato Negrinho","Matthew Gormley","Geoffrey J Gordon","Darshan Patil","Nghia Le","Daniel C. Ferreira"],"categories":null,"content":"","date":1572393600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572393600,"objectID":"07bec4b4eeec94caf472068b9a47405a","permalink":"https://dcferreira.com/publication/deep-architect/","publishdate":"2019-10-30T00:00:00Z","relpermalink":"/publication/deep-architect/","section":"publication","summary":"We propose a formal language for encoding search spaces over general computational graphs, applicable in particular to neural network architecture search.","tags":[],"title":"Towards modular and programmable architecture search","type":"publication"},{"authors":["Félix Iglesias Vázquez","Tanja Zseby","Daniel C. Ferreira","Arthur Zimek"],"categories":null,"content":"","date":1569888e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888e3,"objectID":"92be01b4455e94c39bae18def642b089","permalink":"https://dcferreira.com/publication/mdcgen/","publishdate":"2019-10-30T00:00:00Z","relpermalink":"/publication/mdcgen/","section":"publication","summary":"We present a tool for generating multidimensional synthetic datasets for testing, evaluating, and benchmarking unsupervised classification algorithms.","tags":[],"title":"MDCGen: Multidimensional dataset generator for clustering","type":"publication"},{"authors":["Maximilian Bachl","Daniel C. Ferreira"],"categories":null,"content":"","date":1562112e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562112e3,"objectID":"589124e1206e40ba704b1d84403ab9b1","permalink":"https://dcferreira.com/publication/city-gan/","publishdate":"2019-10-30T00:00:00Z","relpermalink":"/publication/city-gan/","section":"publication","summary":"We use GANs to generate images of buildings' facades, stylized according to a chosen city.","tags":[],"title":"City-GAN: Learning architectural styles using a custom Conditional GAN architecture","type":"publication"},{"authors":null,"categories":null,"content":"Generative Adversarial Networks (GANs) are a well-known technique that is trained on samples (e.g. pictures of fruits) and which after training is able to generate realistic new samples. Conditional GANs (CGANs) additionally provide label information for subclasses (e.g. apple, orange, pear) which enables the GAN to learn more easily and increase the quality of its output samples. We use GANs to learn architectural features of major cities and to generate images of buildings which do not exist. We show that currently available GAN and CGAN architectures are unsuited for this task and propose a custom architecture and demonstrate that our architecture has superior performance for this task and verify its capabilities with extensive experiments.\n","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"482a39f7418c7ee7470038a7fa3a498d","permalink":"https://dcferreira.com/project/city-gan/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/project/city-gan/","section":"project","summary":"City-GAN uses Conditional Generative Adversarial Neural Networks to generate pictures of fake buildings, with the architectural characteristics of a specific city.","tags":["Deep Learning"],"title":"City-GAN","type":"project"},{"authors":["Daniel C. Ferreira","Félix Iglesias Vázquez","Tanja Zseby"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"a4aac82b15bee1f5d798cbfe3d6bb1b7","permalink":"https://dcferreira.com/publication/feature-reduction/","publishdate":"2019-10-30T00:00:00Z","relpermalink":"/publication/feature-reduction/","section":"publication","summary":"We used semi-supervised Autoencoders to obtain 2d visualizations of network traffic that separate between distinct types of attacks.","tags":[],"title":"Extreme Dimensionality Reduction for Network Attack Visualization with Autoencoders","type":"publication"},{"authors":null,"categories":null,"content":"","date":1551916800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551916800,"objectID":"f3e2e8505a3f890c5ffe9840d37e8bb0","permalink":"https://dcferreira.com/project/tfm/","publishdate":"2019-03-07T00:00:00Z","relpermalink":"/project/tfm/","section":"project","summary":"The Traffic Flow Mapper is a prototype tool for visualizing network traffic in 2D.","tags":["Security"],"title":"Traffic Flow Mapper","type":"project"},{"authors":null,"categories":null,"content":"","date":1515283200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515283200,"objectID":"0509e52eaaf4b3b9a8948cd7fb7952f5","permalink":"https://dcferreira.com/project/mdcgenpy/","publishdate":"2018-01-07T00:00:00Z","relpermalink":"/project/mdcgenpy/","section":"project","summary":"MDCGenPy is a synthetic dataset generator made specifically for testing clustering algorithms. It allows for incredible flexibility in generating data with specific shapes with a low effort.","tags":["Clustering"],"title":"MDCGenPy","type":"project"},{"authors":["Daniel C. Ferreira","Félix Iglesias Vázquez","Gernot Vormayr","Maximilian Bachl","Tanja Zseby"],"categories":null,"content":"","date":1502064e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502064e3,"objectID":"3e8b2820ea4e05a56de1769aa014ba2b","permalink":"https://dcferreira.com/publication/ntarc-features/","publishdate":"2020-10-30T00:00:00Z","relpermalink":"/publication/ntarc-features/","section":"publication","summary":"We analyse the used features in network traffic research, and propose a new traffic vector based on how often they are chosen in the literature.","tags":[],"title":"A meta-analysis approach for feature selection in network traffic research","type":"publication"},{"authors":null,"categories":null,"content":"","date":1502064e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502064e3,"objectID":"daae867e75600ed510fe2c812791d08c","permalink":"https://dcferreira.com/project/ntarc/","publishdate":"2017-08-07T00:00:00Z","relpermalink":"/project/ntarc/","section":"project","summary":"The NTARC database is a collective effort of labeling and categorizing research made in the network traffic analysis field.","tags":["Security"],"title":"NTARC Database","type":"project"},{"authors":["Daniel C. Ferreira","André FT Martins","Mariana SC Almeida"],"categories":null,"content":"","date":1470528e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470528e3,"objectID":"27ce786a283d0a51b69801ddc9675806","permalink":"https://dcferreira.com/publication/multilingual/","publishdate":"2019-10-30T00:00:00Z","relpermalink":"/publication/multilingual/","section":"publication","summary":"We propose a joint formulation for learning task-specific cross-lingual word embeddings, along with classifiers for that task. We obtain state of the art results in multiple multilingual datasets.","tags":[],"title":"Jointly Learning to Embed and Predict with Multiple Languages","type":"publication"},{"authors":null,"categories":null,"content":"","date":1470528e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470528e3,"objectID":"5554c872e2ca1ae2a3e10a6be29b0ba7","permalink":"https://dcferreira.com/project/multilingual-embeddings/","publishdate":"2016-08-07T00:00:00Z","relpermalink":"/project/multilingual-embeddings/","section":"project","summary":"Multilingual embeddings can be used for any Natural Language Processing task which applies to multiple languages.","tags":["Machine Learning","NLP"],"title":"Multilingual Embeddings","type":"project"}]