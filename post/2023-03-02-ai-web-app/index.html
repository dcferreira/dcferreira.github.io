<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.4.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><meta name=description content="How and why to make a proof of concept for an AI app, using Jupyter Notebook."><link rel=alternate hreflang=en-us href=https://dcferreira.com/post/2023-03-02-ai-web-app/><meta name=theme-color content="hsl(339, 90%, 68%)"><link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.ad6ecacece4e570505517f526b6aa54a.css><script async src="https://www.googletagmanager.com/gtag/js?id=UA-137896487-1"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(e,t){gtag("event","click",{event_category:"outbound",event_label:e,transport_type:"beacon",event_callback:function(){t!=="_blank"&&(document.location=e)}}),console.debug("Outbound link clicked: "+e)}function onClickCallback(e){if(e.target.tagName!=="A"||e.target.host===window.location.host)return;trackOutboundLink(e.target,e.target.getAttribute("target"))}gtag("js",new Date),gtag("config","UA-137896487-1",{}),gtag("set",{cookie_flags:"SameSite=None;Secure"}),document.addEventListener("click",onClickCallback,!1)</script><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu4876d3cb97a4ad0b3222b8f65edef0fe_436070_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu4876d3cb97a4ad0b3222b8f65edef0fe_436070_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://dcferreira.com/post/2023-03-02-ai-web-app/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@dcferreira1"><meta property="twitter:creator" content="@dcferreira1"><meta property="og:site_name" content="Daniel C Ferreira <dcferreira>"><meta property="og:url" content="https://dcferreira.com/post/2023-03-02-ai-web-app/"><meta property="og:title" content="Making and Deploying an AI Web App in 2023 (Part 2) | Daniel C Ferreira <dcferreira>"><meta property="og:description" content="How and why to make a proof of concept for an AI app, using Jupyter Notebook."><meta property="og:image" content="https://dcferreira.com/media/icon_hu4876d3cb97a4ad0b3222b8f65edef0fe_436070_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://dcferreira.com/media/icon_hu4876d3cb97a4ad0b3222b8f65edef0fe_436070_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-03-08T00:02:00+00:00"><meta property="article:modified_time" content="2023-03-08T00:02:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://dcferreira.com/post/2023-03-02-ai-web-app/"},"headline":"Making and Deploying an AI Web App in 2023 (Part 2)","datePublished":"2023-03-08T00:02:00Z","dateModified":"2023-03-08T00:02:00Z","author":{"@type":"Person","name":"Daniel C. Ferreira"},"publisher":{"@type":"Organization","name":"Daniel C Ferreira \u003cdcferreira\u003e","logo":{"@type":"ImageObject","url":"https://dcferreira.com/media/icon_hu4876d3cb97a4ad0b3222b8f65edef0fe_436070_192x192_fill_lanczos_center_3.png"}},"description":"How and why to make a proof of concept for an AI app, using Jupyter Notebook."}</script><title>Making and Deploying an AI Web App in 2023 (Part 2) | Daniel C Ferreira &lt;dcferreira></title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class="page-wrapper dark" data-wc-page-id=e27ea20c3ee01b2c0aefbc2c84faadbb><script src=/js/wowchemy-init.min.6c07fd79b08c404df0504bd310968f2f.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/#featured><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li></ul></div></nav></header></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>Making and Deploying an AI Web App in 2023 (Part 2)</h1><p class=page-subtitle>Make a Proof of Concept for an AI App</p><div class=article-metadata><div></div><span class=article-date>Mar 8, 2023</span>
<span class=middot-divider></span>
<span class=article-reading-time>4 min read</span>
<span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/ai/>AI</a>, <a href=/category/nlp/>NLP</a></span></div></div><div class=article-container><div class=article-style><div class="alert alert-note"><div><p>This is part of a multi-part blogpost about how to build an AI Web App.
Please refer to <a href=/post/2023-03-01-ai-web-app>Part 1</a> for more context.</p><p>This post uses <a href=https://neuml.github.io/txtai/ target=_blank rel=noopener>txtai</a> as the AI library.</p><p>Alternatives would be: <a href=https://huggingface.co/docs/transformers/index target=_blank rel=noopener>transformers</a>, <a href=https://www.sbert.net/ target=_blank rel=noopener>sentence-transformers</a>, <a href=https://pytorch.org/ target=_blank rel=noopener>PyTorch</a>, <a href=https://keras.io/ target=_blank rel=noopener>Keras</a>, <a href=https://scikit-learn.org/stable/ target=_blank rel=noopener>scikit-learn</a>, among many others.</p></div></div><p>The first step in any project is always to make a proof of concept.
At this stage, we don&rsquo;t care about performance, edge cases, or any other intricaciesâ€”
we just want to confirm that the project is viable.</p><p>For the sake of example, we will take strong inspiration from <a href=https://github.com/neuml/txtai/blob/master/examples/03_Build_an_Embeddings_index_from_a_data_source.ipynb target=_blank rel=noopener>this example from the <code>txtai</code> library</a>.
We&rsquo;ll index a database of documents and then query for them with natural language.
Basically we&rsquo;ll be implementing our own little Google Search, which only returns results from the files we feed it.</p><p>But we won&rsquo;t just search for keywords, like classical search engines.
It&rsquo;s 2023 and we have AI at our disposal!
We will use <a href=https://en.wikipedia.org/wiki/Word_embedding target=_blank rel=noopener>text embeddings</a> to search for the closest match.
By searching for embeddings we&rsquo;re not literally searching for the words we give it, but for the meaning of the whole query.
This is called <a href=https://en.wikipedia.org/wiki/Semantic_search target=_blank rel=noopener>Semantic search</a>.</p><p>So, let&rsquo;s get thing going by creating a new directory for our little project:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mkdir ai-web-app
</span></span><span class=line><span class=cl><span class=nb>cd</span> ai-web-app
</span></span></code></pre></div><p>We will need a database to index and query.
For this example, we will use a test dataset that <code>txtai</code> made available.
This data is a collection of research documents into COVID-19.
The original version of this dataset can be found <a href=https://www.kaggle.com/datasets/allen-institute-for-ai/CORD-19-research-challenge target=_blank rel=noopener>on Kaggle</a>.</p><p>We download the dataset with the following shell commands:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>wget https://github.com/neuml/txtai/releases/download/v1.1.0/tests.gz
</span></span><span class=line><span class=cl>gunzip tests.gz
</span></span><span class=line><span class=cl>mv tests articles.sqlite
</span></span></code></pre></div><p>and install the needed libraries with</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install txtai sentence-transformers pandas jupyterlab
</span></span></code></pre></div><p>We can then start a notebook server with <a href=https://docs.jupyter.org/en/latest/ target=_blank rel=noopener>Jupyter Lab</a> with</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mkdir notebooks <span class=o>&amp;&amp;</span> <span class=nb>cd</span> notebooks <span class=o>&amp;&amp;</span> jupyter lab
</span></span></code></pre></div><p>From our database, we will need to create an index (a searchable database of
documents), and a way to query (search) the index.
The following code (mostly stolen from <a href=https://github.com/neuml/txtai/blob/master/examples/03_Build_an_Embeddings_index_from_a_data_source.ipynb target=_blank rel=noopener><code>txtai</code>&rsquo;s example</a>)
creates an index with the COVID-19 dataset downloaded above:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>sqlite3</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>regex</span> <span class=k>as</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>txtai.embeddings</span> <span class=kn>import</span> <span class=n>Embeddings</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>txtai.pipeline</span> <span class=kn>import</span> <span class=n>Tokenizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>stream</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># Connection to database file</span>
</span></span><span class=line><span class=cl>    <span class=n>db</span> <span class=o>=</span> <span class=n>sqlite3</span><span class=o>.</span><span class=n>connect</span><span class=p>(</span><span class=s2>&#34;../articles.sqlite&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>cur</span> <span class=o>=</span> <span class=n>db</span><span class=o>.</span><span class=n>cursor</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Select tagged sentences without a NLP label. NLP labels are set for non-informative sentences.</span>
</span></span><span class=line><span class=cl>    <span class=n>cur</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=s2>&#34;SELECT Id, Name, Text FROM sections WHERE (labels is null or labels NOT IN (&#39;FRAGMENT&#39;, &#39;QUESTION&#39;)) AND tags is not null&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>count</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>cur</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Unpack row</span>
</span></span><span class=line><span class=cl>        <span class=n>uid</span><span class=p>,</span> <span class=n>name</span><span class=p>,</span> <span class=n>text</span> <span class=o>=</span> <span class=n>row</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Only process certain document sections</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=n>name</span> <span class=ow>or</span> <span class=ow>not</span> <span class=n>re</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=sa>r</span><span class=s2>&#34;background|(?&lt;!.*?results.*?)discussion|introduction|reference&#34;</span><span class=p>,</span> <span class=n>name</span><span class=o>.</span><span class=n>lower</span><span class=p>()):</span>
</span></span><span class=line><span class=cl>            <span class=c1># Tokenize text</span>
</span></span><span class=line><span class=cl>            <span class=n>tokens</span> <span class=o>=</span> <span class=n>Tokenizer</span><span class=o>.</span><span class=n>tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>document</span> <span class=o>=</span> <span class=p>(</span><span class=n>uid</span><span class=p>,</span> <span class=n>tokens</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>count</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>count</span> <span class=o>%</span> <span class=mi>1000</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Streamed </span><span class=si>%d</span><span class=s2> documents&#34;</span> <span class=o>%</span> <span class=p>(</span><span class=n>count</span><span class=p>),</span> <span class=n>end</span><span class=o>=</span><span class=s2>&#34;</span><span class=se>\r</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Skip documents with no tokens parsed</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>tokens</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>yield</span> <span class=n>document</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Iterated over </span><span class=si>%d</span><span class=s2> total rows&#34;</span> <span class=o>%</span> <span class=p>(</span><span class=n>count</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Free database resources</span>
</span></span><span class=line><span class=cl>    <span class=n>db</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># BM25 + fastText vectors</span>
</span></span><span class=line><span class=cl><span class=n>embeddings</span> <span class=o>=</span> <span class=n>Embeddings</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;method&#34;</span><span class=p>:</span> <span class=s2>&#34;sentence-transformers&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;path&#34;</span><span class=p>:</span> <span class=s2>&#34;all-MiniLM-L6-v2&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;scoring&#34;</span><span class=p>:</span> <span class=s2>&#34;bm25&#34;</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>embeddings</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>stream</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>embeddings</span><span class=o>.</span><span class=n>index</span><span class=p>(</span><span class=n>stream</span><span class=p>())</span>
</span></span></code></pre></div><p>In the code above, the text embeddings are generated using the <a href=https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2 target=_blank rel=noopener><code>all-MiniLM-L6-v2</code> model</a>.
We could also train our own model instead of using a pre-trained model, but that
would require a lot of work.
If we can avoid it, why not?</p><p>So at this point, we have a database and want to search it.
In the following cell, we define a Python function to query the index for the closest results, and then query the original data for extra information about the results.
The last thing we do in this cell is to search for <code>"risk factors"</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>pd</span><span class=o>.</span><span class=n>set_option</span><span class=p>(</span><span class=s2>&#34;display.max_colwidth&#34;</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>search</span><span class=p>(</span><span class=n>query</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>topn</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>5</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>db</span> <span class=o>=</span> <span class=n>sqlite3</span><span class=o>.</span><span class=n>connect</span><span class=p>(</span><span class=s2>&#34;../articles.sqlite&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>cur</span> <span class=o>=</span> <span class=n>db</span><span class=o>.</span><span class=n>cursor</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>uid</span><span class=p>,</span> <span class=n>score</span> <span class=ow>in</span> <span class=n>embeddings</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=n>query</span><span class=p>,</span> <span class=n>topn</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>cur</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=s2>&#34;SELECT article, text FROM sections WHERE id = ?&#34;</span><span class=p>,</span> <span class=p>[</span><span class=n>uid</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>uid</span><span class=p>,</span> <span class=n>text</span> <span class=o>=</span> <span class=n>cur</span><span class=o>.</span><span class=n>fetchone</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>cur</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=s2>&#34;SELECT Title, Published, Reference from articles where id = ?&#34;</span><span class=p>,</span> <span class=p>[</span><span class=n>uid</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>cur</span><span class=o>.</span><span class=n>fetchone</span><span class=p>()</span> <span class=o>+</span> <span class=p>(</span><span class=n>text</span><span class=p>,))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>db</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>results</span><span class=p>,</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;Title&#34;</span><span class=p>,</span> <span class=s2>&#34;Published&#34;</span><span class=p>,</span> <span class=s2>&#34;Reference&#34;</span><span class=p>,</span> <span class=s2>&#34;Match&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>df</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>search</span><span class=p>(</span><span class=s2>&#34;risk factors&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>The output of that cell will be a pandas dataframe with the results:<figure><div class="d-flex justify-content-center"><div class=w-100><img src=/assets/ai-web-app/image_1674755971020_0.png alt=image.png loading=lazy data-zoomable></div></div></figure></p><p>We can also try other queries:<figure><div class="d-flex justify-content-center"><div class=w-100><img src=/assets/ai-web-app/image_1674755993542_0.png alt=image.png loading=lazy data-zoomable></div></div></figure><figure><div class="d-flex justify-content-center"><div class=w-100><img src=/assets/ai-web-app/image_1674756005367_0.png alt=image.png loading=lazy data-zoomable></div></div></figure></p><p>As you can see, while the results maybe aren&rsquo;t the best, they are good enough for our proof of concept.
We could spend a lot more time making this part better, but in the spirit of <a href=https://www.ycombinator.com/library/40-the-art-of-shipping-early-and-often target=_blank rel=noopener>shipping early and often</a>, this is enough for now.</p><div class="alert alert-note"><div>If you&rsquo;ve been following these instructions, your code should look like this:
<a href=https://github.com/dcferreira/ai-web-app/tree/19cda18ea099d46716b280694eed2677ef680e5d target=_blank rel=noopener>https://github.com/dcferreira/ai-web-app/tree/19cda18ea099d46716b280694eed2677ef680e5d</a></div></div><p>To continue this tutorial, go to <a href=/post/2023-03-03-ai-web-app>Part 3</a>.</p><p>For comments or questions, use the
<a href=https://www.reddit.com/user/dlcferreira/comments/11mv2k9/making_and_deploying_an_ai_web_app_in_2023_part_2/ target=_blank rel=noopener>Reddit discussion</a>
or reach out to me <a href=mailto:daniel.ferreira.1@gmail.com>directly via email</a>.</p></div><div class=article-tags><a class="badge badge-light" href=/tag/ai/>AI</a>
<a class="badge badge-light" href=/tag/machine-learning/>Machine Learning</a>
<a class="badge badge-light" href=/tag/web-app/>Web App</a>
<a class="badge badge-light" href=/tag/txtai/>txtai</a>
<a class="badge badge-light" href=/tag/web-development/>Web Development</a>
<a class="badge badge-light" href=/tag/serverless/>Serverless</a>
<a class="badge badge-light" href=/tag/nlp/>NLP</a></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> â€” the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.3d946de2e8784a477845261d87025092.js></script>
<script src=https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/latex.min.js crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.e8fd2d733eef6a8bbbe0539398fc0547.js type=module></script>
<script src=/en/js/wowchemy.min.9162604ef5b82e6fdeff386200ab6db9.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.b0d291ed6d27eacec233e6cf5204f99a.js type=module></script></body></html>