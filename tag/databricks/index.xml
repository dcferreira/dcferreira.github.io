<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Databricks | dcferreira</title><link>https://dcferreira.com/tag/databricks/</link><atom:link href="https://dcferreira.com/tag/databricks/index.xml" rel="self" type="application/rss+xml"/><description>Databricks</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 21 Mar 2022 17:30:00 +0000</lastBuildDate><image><url>https://dcferreira.com/media/icon_hu17a6451f2bd4dca1ddd6241c7ddf07a6_3179_512x512_fill_lanczos_center_3.png</url><title>Databricks</title><link>https://dcferreira.com/tag/databricks/</link></image><item><title>Efficient UDFs on Databricks with unpickleable objects</title><link>https://dcferreira.com/post/2022-03-spark-serialization/</link><pubDate>Mon, 21 Mar 2022 17:30:00 +0000</pubDate><guid>https://dcferreira.com/post/2022-03-spark-serialization/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>I often run into a problem when writing UDFs on Databricks, where I need some to access some object that &lt;code>pickle&lt;/code> can&amp;rsquo;t serialize.
Often times this is just something that comes from some external library, and so fixing the code is not a practical solution.&lt;/p>
&lt;p>An easy solution to this is to initialize the object inside the UDF itself.
This avoids the need for serialization, but it introduces a new problem: the object is initialized for every run of the UDF, hitting performance.&lt;/p>
&lt;p>The solution that addresses these 2 problems is to cache the object initialization.
Then, each executor initializes the object only once.&lt;/p>
&lt;h2 id="the-problem">The Problem&lt;/h2>
&lt;p>Here is a simple example:&lt;/p>
&lt;pre>&lt;code class="language-python">import time
from lxml.etree import HTMLParser
# `spark` is the spark context, on databricks it is a global variable that's always available
df = spark.createDataFrame([{&amp;quot;n&amp;quot;: n} for n in range(10000)])
class Slow:
def __init__(self):
self.parser = HTMLParser()
time.sleep(0.01)
def double(self, x: int) -&amp;gt; int:
return 2 * x
slow_global = Slow()
@udf(&amp;quot;int&amp;quot;)
def f_error(n):
return slow_global.double(n)
&lt;/code>&lt;/pre>
&lt;p>When actually executing the UDF&lt;/p>
&lt;pre>&lt;code class="language-python">df.select(&amp;quot;n&amp;quot;, f_error(&amp;quot;n&amp;quot;)).collect()
&lt;/code>&lt;/pre>
&lt;p>we get the error&lt;/p>
&lt;pre>&lt;code>PicklingError: Could not serialize object: TypeError: can't pickle lxml.etree.HTMLParser objects
&lt;/code>&lt;/pre>
&lt;h2 id="naive-solution">Naive Solution&lt;/h2>
&lt;p>The naive solution is to initialize the object in each run of the UDF:&lt;/p>
&lt;pre>&lt;code class="language-python">@udf(&amp;quot;int&amp;quot;)
def f(n):
slow = Slow()
return slow.double(n)
&lt;/code>&lt;/pre>
&lt;p>This works&lt;/p>
&lt;pre>&lt;code class="language-python">df.select(&amp;quot;n&amp;quot;, f(&amp;quot;n&amp;quot;)).collect()
&lt;/code>&lt;/pre>
&lt;p>but it&amp;rsquo;s very inefficient.&lt;/p>
&lt;p>On a cluster with 2 &lt;code>i3.xlarge&lt;/code> workers on AWS, executing this took me around 25 seconds.&lt;/p>
&lt;h2 id="optimized-solution">Optimized Solution&lt;/h2>
&lt;p>The solution is then to cache the object initialization.
For this, we need the &lt;a href="https://cachetools.readthedocs.io/" target="_blank" rel="noopener">&lt;code>cachetools&lt;/code>&lt;/a> library.
On Databricks, you can install it by running the following cell&lt;/p>
&lt;pre>&lt;code>%pip install cachetools
&lt;/code>&lt;/pre>
&lt;div class="alert alert-note">
&lt;div>
We can&amp;rsquo;t use &lt;a href="https://docs.python.org/3/library/functools.html#functools.lru_cache" target="_blank" rel="noopener">&lt;code>lru_cache&lt;/code>&lt;/a> from the standard library,
because it requires serialization.
Trying it gives us the error: &lt;code>PicklingError: Could not serialize object: AttributeError: 'functools._lru_cache_wrapper' object has no attribute '__bases__'&lt;/code>
&lt;/div>
&lt;/div>
&lt;p>Usage is very simple:&lt;/p>
&lt;pre>&lt;code class="language-python">from cachetools import cached
@cached(cache={})
def get_slow():
return Slow()
@udf(&amp;quot;int&amp;quot;)
def f_cached(n):
slow = get_slow()
return slow.double(n)
&lt;/code>&lt;/pre>
&lt;p>Executing it&lt;/p>
&lt;pre>&lt;code class="language-python">df.select(&amp;quot;n&amp;quot;, f_cached(&amp;quot;n&amp;quot;)).collect()
&lt;/code>&lt;/pre>
&lt;p>took around 0.5 seconds, in the same cluster as above.&lt;/p></description></item></channel></rss>